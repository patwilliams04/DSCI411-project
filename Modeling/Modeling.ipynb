{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "15156441-f8f5-4ea1-b7be-da07e6f2d1b6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('/Users/patwilliams/DSCI441/DSCI411-project/Data_PreProcessing/final_economic_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c3efe9e7-937b-42b0-8862-7c40f7705adb",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Year</th>\n",
       "      <th>Annual_%_Change_nasdaq</th>\n",
       "      <th>Annual_%_Change_dowj</th>\n",
       "      <th>Annual_%_Change_sp500</th>\n",
       "      <th>Annual_%_Change_corn</th>\n",
       "      <th>Annual_%_Change_cotton</th>\n",
       "      <th>Annual_%_Change_pound</th>\n",
       "      <th>Annual_%_Change_yen</th>\n",
       "      <th>Annual_Unemployment_Rate</th>\n",
       "      <th>Annual_%_Change_silver</th>\n",
       "      <th>...</th>\n",
       "      <th>Annual_%_Change_FFRate</th>\n",
       "      <th>Annual_%_Change_tenyrRate</th>\n",
       "      <th>Annual_%_Change_oneyrRate</th>\n",
       "      <th>Annual_%_Change_gold</th>\n",
       "      <th>Annual_%_Change_crude</th>\n",
       "      <th>Annual_%_Change_copper</th>\n",
       "      <th>Annual_%_Change_coffee</th>\n",
       "      <th>Unemployment_Rate_Increased</th>\n",
       "      <th>Unemployment_Rate_Percent_Change</th>\n",
       "      <th>Unemployment_Rate_Change_Indicator</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2024.0</td>\n",
       "      <td>9.05</td>\n",
       "      <td>5.55</td>\n",
       "      <td>9.89</td>\n",
       "      <td>-6.53</td>\n",
       "      <td>13.58</td>\n",
       "      <td>-0.51</td>\n",
       "      <td>6.85</td>\n",
       "      <td>3.800000</td>\n",
       "      <td>-0.092688</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.223298</td>\n",
       "      <td>0.262182</td>\n",
       "      <td>-0.145917</td>\n",
       "      <td>-0.144743</td>\n",
       "      <td>0.056138</td>\n",
       "      <td>-0.134274</td>\n",
       "      <td>-0.345731</td>\n",
       "      <td>1</td>\n",
       "      <td>4.827586</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2023.0</td>\n",
       "      <td>43.42</td>\n",
       "      <td>13.70</td>\n",
       "      <td>24.23</td>\n",
       "      <td>-30.62</td>\n",
       "      <td>-2.41</td>\n",
       "      <td>5.22</td>\n",
       "      <td>7.56</td>\n",
       "      <td>3.625000</td>\n",
       "      <td>-0.229543</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.070694</td>\n",
       "      <td>-0.082794</td>\n",
       "      <td>-0.199847</td>\n",
       "      <td>0.188286</td>\n",
       "      <td>-0.582778</td>\n",
       "      <td>-0.166927</td>\n",
       "      <td>0.208869</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.229358</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2022.0</td>\n",
       "      <td>-33.10</td>\n",
       "      <td>-8.78</td>\n",
       "      <td>-19.44</td>\n",
       "      <td>14.37</td>\n",
       "      <td>-26.29</td>\n",
       "      <td>-10.52</td>\n",
       "      <td>13.91</td>\n",
       "      <td>3.633333</td>\n",
       "      <td>-0.124077</td>\n",
       "      <td>...</td>\n",
       "      <td>6.297961</td>\n",
       "      <td>3.488887</td>\n",
       "      <td>3.026747</td>\n",
       "      <td>-0.340666</td>\n",
       "      <td>-0.128344</td>\n",
       "      <td>-0.646130</td>\n",
       "      <td>-0.838549</td>\n",
       "      <td>0</td>\n",
       "      <td>-31.981279</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2021.0</td>\n",
       "      <td>21.39</td>\n",
       "      <td>18.73</td>\n",
       "      <td>26.89</td>\n",
       "      <td>22.57</td>\n",
       "      <td>44.14</td>\n",
       "      <td>-1.23</td>\n",
       "      <td>11.49</td>\n",
       "      <td>5.341667</td>\n",
       "      <td>-0.569481</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.370152</td>\n",
       "      <td>2.094849</td>\n",
       "      <td>3.026747</td>\n",
       "      <td>-0.471016</td>\n",
       "      <td>1.052936</td>\n",
       "      <td>0.566733</td>\n",
       "      <td>1.624098</td>\n",
       "      <td>0</td>\n",
       "      <td>-33.985582</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2020.0</td>\n",
       "      <td>43.64</td>\n",
       "      <td>7.25</td>\n",
       "      <td>16.26</td>\n",
       "      <td>24.82</td>\n",
       "      <td>13.14</td>\n",
       "      <td>3.21</td>\n",
       "      <td>-5.00</td>\n",
       "      <td>8.091667</td>\n",
       "      <td>1.282133</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.845809</td>\n",
       "      <td>-1.852644</td>\n",
       "      <td>-1.742681</td>\n",
       "      <td>0.639346</td>\n",
       "      <td>-0.807901</td>\n",
       "      <td>0.536434</td>\n",
       "      <td>-0.237071</td>\n",
       "      <td>1</td>\n",
       "      <td>120.181406</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Year  Annual_%_Change_nasdaq  Annual_%_Change_dowj  \\\n",
       "0  2024.0                    9.05                  5.55   \n",
       "1  2023.0                   43.42                 13.70   \n",
       "2  2022.0                  -33.10                 -8.78   \n",
       "3  2021.0                   21.39                 18.73   \n",
       "4  2020.0                   43.64                  7.25   \n",
       "\n",
       "   Annual_%_Change_sp500  Annual_%_Change_corn  Annual_%_Change_cotton  \\\n",
       "0                   9.89                 -6.53                   13.58   \n",
       "1                  24.23                -30.62                   -2.41   \n",
       "2                 -19.44                 14.37                  -26.29   \n",
       "3                  26.89                 22.57                   44.14   \n",
       "4                  16.26                 24.82                   13.14   \n",
       "\n",
       "   Annual_%_Change_pound  Annual_%_Change_yen  Annual_Unemployment_Rate  \\\n",
       "0                  -0.51                 6.85                  3.800000   \n",
       "1                   5.22                 7.56                  3.625000   \n",
       "2                 -10.52                13.91                  3.633333   \n",
       "3                  -1.23                11.49                  5.341667   \n",
       "4                   3.21                -5.00                  8.091667   \n",
       "\n",
       "   Annual_%_Change_silver  ...  Annual_%_Change_FFRate  \\\n",
       "0               -0.092688  ...               -0.223298   \n",
       "1               -0.229543  ...               -0.070694   \n",
       "2               -0.124077  ...                6.297961   \n",
       "3               -0.569481  ...               -0.370152   \n",
       "4                1.282133  ...               -0.845809   \n",
       "\n",
       "   Annual_%_Change_tenyrRate  Annual_%_Change_oneyrRate  Annual_%_Change_gold  \\\n",
       "0                   0.262182                  -0.145917             -0.144743   \n",
       "1                  -0.082794                  -0.199847              0.188286   \n",
       "2                   3.488887                   3.026747             -0.340666   \n",
       "3                   2.094849                   3.026747             -0.471016   \n",
       "4                  -1.852644                  -1.742681              0.639346   \n",
       "\n",
       "   Annual_%_Change_crude  Annual_%_Change_copper  Annual_%_Change_coffee  \\\n",
       "0               0.056138               -0.134274               -0.345731   \n",
       "1              -0.582778               -0.166927                0.208869   \n",
       "2              -0.128344               -0.646130               -0.838549   \n",
       "3               1.052936                0.566733                1.624098   \n",
       "4              -0.807901                0.536434               -0.237071   \n",
       "\n",
       "   Unemployment_Rate_Increased  Unemployment_Rate_Percent_Change  \\\n",
       "0                            1                          4.827586   \n",
       "1                            0                         -0.229358   \n",
       "2                            0                        -31.981279   \n",
       "3                            0                        -33.985582   \n",
       "4                            1                        120.181406   \n",
       "\n",
       "   Unemployment_Rate_Change_Indicator  \n",
       "0                                   0  \n",
       "1                                   0  \n",
       "2                                   1  \n",
       "3                                   1  \n",
       "4                                   1  \n",
       "\n",
       "[5 rows x 21 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "66e2aa1b-8092-48de-bee7-5a22a9624e8b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((40, 16), (10, 16), (40,), (10,), (1, 21))"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Assuming the DataFrame is already sorted by year\n",
    "# Extract the row for the holdout set (the most recent year, 2024)\n",
    "holdout = df[df['Year'] == 2024]\n",
    "\n",
    "# Remove the holdout set from the main DataFrame\n",
    "df_modeling = df[df['Year'] != 2024]\n",
    "\n",
    "# IF YEAR SHOULD BE INCORPORATED\n",
    "\n",
    "# Calculate 'Years Since Epoch' where Epoch is set to 1974\n",
    "#df['Years_Since_Epoch'] = df['Year'] - 1974\n",
    "# Display the updated DataFrame to verify the transformation\n",
    "#df[['Year', 'Years_Since_Epoch']].head()\n",
    "\n",
    "\n",
    "# Define the features and target\n",
    "X = df_modeling.drop(['Annual_Unemployment_Rate', 'Year', 'Unemployment_Rate_Increased', 'Unemployment_Rate_Percent_Change', 'Unemployment_Rate_Change_Indicator'], axis=1) # should year be included?? Is it better to include as t starting with t = 0... t+1\n",
    "y = df_modeling['Annual_Unemployment_Rate']\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "# We want 40 observations in the training set, and 10 in the test set\n",
    "# The dataset is already sorted by year, so we can split accordingly\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=10, shuffle=False)\n",
    "\n",
    "# Check the shapes to confirm the sizes\n",
    "(X_train.shape, X_test.shape, y_train.shape, y_test.shape, holdout.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28c3d7fe-d6d0-40ee-bb91-36d48bfc109b",
   "metadata": {},
   "source": [
    "### AdaBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4440a598-d516-480e-91c0-c86c7eb3cb73",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 2.923\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.ensemble import AdaBoostRegressor\n",
    "\n",
    "reg_ada = AdaBoostRegressor(n_estimators=10, random_state=500)\n",
    "reg_ada.fit(X_train, y_train)\n",
    "\n",
    "# Calculate the predictions on the test set\n",
    "pred = reg_ada.predict(X_test)\n",
    "\n",
    "# Evaluate the performance using the RMSE\n",
    "rmse = np.sqrt(mean_squared_error(y_test, pred))\n",
    "print('RMSE: {:.3f}'.format(rmse))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74ea80b6-b740-47b1-a64e-1d6842df03cb",
   "metadata": {},
   "source": [
    "### GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9e7361c9-dc13-4e55-b8a1-d1941e93d6e6",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters: {'learning_rate': 1.0, 'n_estimators': 5}\n",
      "Best cross-validation R^2: -1.5222325768831293\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# Define the parameter grid\n",
    "param_grid = {\n",
    "    'n_estimators': [5, 10, 50, 100, 150, 200],\n",
    "    'learning_rate': [0.005, 0.01, 0.1, 0.5, 1.0]\n",
    "\n",
    "}\n",
    "\n",
    "# Initialize the AdaBoostRegressor\n",
    "reg_ada = AdaBoostRegressor(random_state=500)\n",
    "\n",
    "# Initialize GridSearchCV\n",
    "grid_search = GridSearchCV(estimator=reg_ada, param_grid=param_grid, cv=5, scoring='r2')\n",
    "\n",
    "# Fit GridSearchCV\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Best parameter and score\n",
    "print(\"Best parameters:\", grid_search.best_params_)\n",
    "print(\"Best cross-validation R^2:\", grid_search.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a13da68a-2435-4f72-b307-9e35b2edad9f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best AdaBoost Model Performance Metrics:\n",
      "Mean Squared Error (MSE): 7.767\n",
      "Mean Absolute Error (MAE): 2.493\n",
      "Root Mean Squared Error (RMSE): 2.787\n",
      "R-squared (R2): -3.125\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "best_ada = grid_search.best_estimator_\n",
    "\n",
    "# Make predictions using the best model on the test set\n",
    "pred = best_ada.predict(X_test)\n",
    "\n",
    "# Calculate various performance metrics\n",
    "mse = mean_squared_error(y_test, pred)\n",
    "mae = mean_absolute_error(y_test, pred)\n",
    "rmse = np.sqrt(mse)\n",
    "r2 = r2_score(y_test, pred)\n",
    "\n",
    "# Print the performance metrics\n",
    "print(\"Best AdaBoost Model Performance Metrics:\")\n",
    "print(\"Mean Squared Error (MSE): {:.3f}\".format(mse))\n",
    "print(\"Mean Absolute Error (MAE): {:.3f}\".format(mae))\n",
    "print(\"Root Mean Squared Error (RMSE): {:.3f}\".format(rmse))\n",
    "print(\"R-squared (R2): {:.3f}\".format(r2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "268eeef9-551a-497b-a554-2bb21e287c1d",
   "metadata": {},
   "source": [
    "### GradientBoostRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6c5ee52d-7c08-4f26-a88c-4bd328d0b0a7",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient Boosting Model Performance Metrics:\n",
      "Mean Squared Error (MSE): 4.540\n",
      "Mean Absolute Error (MAE): 1.737\n",
      "Root Mean Squared Error (RMSE): 2.131\n",
      "R-squared (R2): -1.411\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "\n",
    "# Define GradientBoosting parameters to tune\n",
    "param_grid = {\n",
    "    'n_estimators': [5, 10, 50, 100, 200, 300],\n",
    "    'learning_rate': [0.01, 0.02, 0.1, 0.2, 0.3, 0.5],\n",
    "    'max_depth': [3, 4, 5, 6, 7, 8],\n",
    "    'subsample': [0.5, 0.6, 0.7, 0.8, 0.9, 1.0]  # Percentage of samples used for fitting the individual base learners\n",
    "}\n",
    "\n",
    "# Initialize the GradientBoostingRegressor\n",
    "reg_gb = GradientBoostingRegressor(random_state=500)\n",
    "\n",
    "# Initialize GridSearchCV\n",
    "grid_search_gb = GridSearchCV(estimator=reg_gb, param_grid=param_grid, cv=5, scoring='r2')\n",
    "\n",
    "# Fit GridSearchCV to the training data\n",
    "grid_search_gb.fit(X_train, y_train)\n",
    "\n",
    "# Retrieve the best model from GridSearchCV\n",
    "best_gb = grid_search_gb.best_estimator_\n",
    "\n",
    "# Make predictions using the best model on the test set\n",
    "pred_gb = best_gb.predict(X_test)\n",
    "\n",
    "# Calculate various performance metrics\n",
    "mse_gb = mean_squared_error(y_test, pred_gb)\n",
    "mae_gb = mean_absolute_error(y_test, pred_gb)\n",
    "rmse_gb = np.sqrt(mse_gb)\n",
    "r2_gb = r2_score(y_test, pred_gb)\n",
    "\n",
    "# Print the performance metrics\n",
    "print(\"Gradient Boosting Model Performance Metrics:\")\n",
    "print(\"Mean Squared Error (MSE): {:.3f}\".format(mse_gb))\n",
    "print(\"Mean Absolute Error (MAE): {:.3f}\".format(mae_gb))\n",
    "print(\"Root Mean Squared Error (RMSE): {:.3f}\".format(rmse_gb))\n",
    "print(\"R-squared (R2): {:.3f}\".format(r2_gb))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8fbe2c13-4a09-49cd-b5ac-d5c1b94e1925",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters: {'learning_rate': 0.1, 'max_depth': 6, 'n_estimators': 5, 'subsample': 0.5}\n",
      "Best cross-validation R^2: -1.1856265856398154\n"
     ]
    }
   ],
   "source": [
    "print(\"Best parameters:\", grid_search_gb.best_params_)\n",
    "print(\"Best cross-validation R^2:\", grid_search_gb.best_score_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7268e5a7-5c51-4601-8cf2-50ab50deae4f",
   "metadata": {},
   "source": [
    "### XGBoostRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "dd6e3dbd-4e72-4bec-af9b-5c5d9b30343a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGBoost Model Performance Metrics:\n",
      "Mean Squared Error (MSE): 4.854\n",
      "Mean Absolute Error (MAE): 1.806\n",
      "Root Mean Squared Error (RMSE): 2.203\n",
      "R-squared (R2): -1.578\n"
     ]
    }
   ],
   "source": [
    "from xgboost import XGBRegressor\n",
    "\n",
    "# Define XGBRegressor parameters to tune\n",
    "param_grid = {\n",
    "    'n_estimators': [5, 10, 50, 100, 200, 300],\n",
    "    'learning_rate': [0.01, 0.02, 0.1, 0.2, 0.3, 0.5],\n",
    "    'max_depth': [3, 4, 5, 6, 7, 8],\n",
    "    'subsample': [0.5, 0.6, 0.7, 0.8, 0.9, 1.0],\n",
    "    'colsample_bytree': [0.5,0.6,0.7, 0.8, 0.9]  # Percentage of features used per tree\n",
    "}\n",
    "\n",
    "# Initialize the XGBRegressor\n",
    "reg_xgb = XGBRegressor(random_state=500)\n",
    "\n",
    "# Initialize GridSearchCV\n",
    "grid_search_xgb = GridSearchCV(estimator=reg_xgb, param_grid=param_grid, cv=5, scoring='r2')\n",
    "\n",
    "# Fit GridSearchCV to the training data\n",
    "grid_search_xgb.fit(X_train, y_train)\n",
    "\n",
    "# Retrieve the best model from GridSearchCV\n",
    "best_xgb = grid_search_xgb.best_estimator_\n",
    "\n",
    "# Make predictions using the best model on the test set\n",
    "pred_xgb = best_xgb.predict(X_test)\n",
    "\n",
    "# Calculate various performance metrics\n",
    "mse_xgb = mean_squared_error(y_test, pred_xgb)\n",
    "mae_xgb = mean_absolute_error(y_test, pred_xgb)\n",
    "rmse_xgb = np.sqrt(mse_xgb)\n",
    "r2_xgb = r2_score(y_test, pred_xgb)\n",
    "\n",
    "# Print the performance metrics\n",
    "print(\"XGBoost Model Performance Metrics:\")\n",
    "print(\"Mean Squared Error (MSE): {:.3f}\".format(mse_xgb))\n",
    "print(\"Mean Absolute Error (MAE): {:.3f}\".format(mae_xgb))\n",
    "print(\"Root Mean Squared Error (RMSE): {:.3f}\".format(rmse_xgb))\n",
    "print(\"R-squared (R2): {:.3f}\".format(r2_xgb))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ba21ea79-9ca2-4f64-9bbe-e4a1e1c3f25c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters: {'colsample_bytree': 0.6, 'learning_rate': 0.2, 'max_depth': 3, 'n_estimators': 5, 'subsample': 1.0}\n",
      "Best cross-validation R^2: -1.1035481647946999\n"
     ]
    }
   ],
   "source": [
    "print(\"Best parameters:\", grid_search_xgb.best_params_)\n",
    "print(\"Best cross-validation R^2:\", grid_search_xgb.best_score_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8916779-037b-491e-9c60-016177b39ba3",
   "metadata": {},
   "source": [
    "# Classification Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "3f2d35b7-eb05-4102-bf55-de0195f7169f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df3 = pd.read_csv('/Users/patwilliams/DSCI441/DSCI411-project/Data_PreProcessing/final_economic_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c8de68fa-3c2c-4a39-b048-1d4ec306644b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((40, 16), (10, 16), (40,), (10,), (1, 21))"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "holdout = df3[df3['Year'] == 2024]\n",
    "\n",
    "# Remove the holdout set from the main DataFrame\n",
    "df_modeling = df3[df3['Year'] != 2024]\n",
    "\n",
    "# IF YEAR SHOULD BE INCORPORATED\n",
    "\n",
    "# Calculate 'Years Since Epoch' where Epoch is set to 1974\n",
    "#df['Years_Since_Epoch'] = df['Year'] - 1974\n",
    "# Display the updated DataFrame to verify the transformation\n",
    "#df[['Year', 'Years_Since_Epoch']].head()\n",
    "\n",
    "\n",
    "# Define the features and target\n",
    "X = df_modeling.drop(['Annual_Unemployment_Rate', 'Year', 'Unemployment_Rate_Increased', 'Unemployment_Rate_Percent_Change', 'Unemployment_Rate_Change_Indicator'], axis=1) # should year be included?? Is it better to include as t starting with t = 0... t+1\n",
    "y = df_modeling['Unemployment_Rate_Increased']\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "# We want 40 observations in the training set, and 10 in the test set\n",
    "# The dataset is already sorted by year, so we can split accordingly\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=10, shuffle=False)\n",
    "\n",
    "# Check the shapes to confirm the sizes\n",
    "(X_train.shape, X_test.shape, y_train.shape, y_test.shape, holdout.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e59a7bef-1c0a-4375-89f9-ff0ef2172c57",
   "metadata": {},
   "source": [
    "#### If going to use holdout for prediction, must drop out the year, unemployment rate, and the binary created"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "238d2b34-ad0f-4d73-8c53-069289a3bdef",
   "metadata": {},
   "source": [
    "### AdaBoostClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "ab3432a3-ac3b-4f96-8104-7682eb3c47c2",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Classifier Model Performance Metrics:\n",
      "Accuracy: 0.500\n",
      "Precision: 0.000\n",
      "Recall: 0.000\n",
      "F1 Score: 0.000\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "# Define AdaBoost parameters to tune\n",
    "param_grid = {\n",
    "    'n_estimators': [5, 10, 50, 100, 150, 200],\n",
    "    'learning_rate': [0.005, 0.01, 0.1, 0.5, 1.0]\n",
    "}\n",
    "\n",
    "# Initialize the AdaBoostClassifier\n",
    "clf_ada = AdaBoostClassifier(random_state=500)\n",
    "\n",
    "# Initialize GridSearchCV with 'accuracy' as the scoring metric\n",
    "grid_search_clf = GridSearchCV(estimator=clf_ada, param_grid=param_grid, cv=5, scoring='accuracy')\n",
    "\n",
    "# Fit GridSearchCV to the training data\n",
    "grid_search_clf.fit(X_train, y_train)\n",
    "\n",
    "# Retrieve the best model\n",
    "best_ada_clf = grid_search_clf.best_estimator_\n",
    "\n",
    "# Make predictions using the best model on the test set\n",
    "pred_clf = best_ada_clf.predict(X_test)\n",
    "\n",
    "# Calculate various performance metrics\n",
    "accuracy = accuracy_score(y_test, pred_clf)\n",
    "precision = precision_score(y_test, pred_clf)\n",
    "recall = recall_score(y_test, pred_clf)\n",
    "f1 = f1_score(y_test, pred_clf)\n",
    "\n",
    "# Print the performance metrics\n",
    "print(\"Best Classifier Model Performance Metrics:\")\n",
    "print(\"Accuracy: {:.3f}\".format(accuracy))\n",
    "print(\"Precision: {:.3f}\".format(precision))\n",
    "print(\"Recall: {:.3f}\".format(recall))\n",
    "print(\"F1 Score: {:.3f}\".format(f1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "7d10bb38-c900-4f92-986b-9e93b3940b1c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters: {'learning_rate': 1.0, 'n_estimators': 10}\n",
      "Best cross-validation accuracy: 0.75\n"
     ]
    }
   ],
   "source": [
    "print(\"Best parameters:\", grid_search_clf.best_params_)\n",
    "print(\"Best cross-validation accuracy:\", grid_search_clf.best_score_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db243ede-fea7-4b3d-a8dd-5856e76c129e",
   "metadata": {},
   "source": [
    "### GradientBoostingClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "c25f6951-4a92-4674-9608-8fd4d0c01185",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient Boosting Classifier Model Performance Metrics:\n",
      "Accuracy: 0.700\n",
      "Precision: 1.000\n",
      "Recall: 0.250\n",
      "F1 Score: 0.400\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "\n",
    "# Define GradientBoosting parameters to tune\n",
    "param_grid = {\n",
    "    'n_estimators': [5, 10, 50, 100, 200, 300],\n",
    "    'learning_rate': [0.01, 0.02, 0.1, 0.2, 0.3, 0.5],\n",
    "    'max_depth': [3, 4, 5, 6, 7, 8],\n",
    "    'subsample': [0.5, 0.6, 0.7, 0.8, 0.9, 1.0]  # Percentage of samples used for fitting the individual base learners\n",
    "}\n",
    "\n",
    "# Initialize the GradientBoostingClassifier\n",
    "clf_gb = GradientBoostingClassifier(random_state=500)\n",
    "\n",
    "# Initialize GridSearchCV with 'accuracy' as the scoring metric\n",
    "grid_search_clf_gb = GridSearchCV(estimator=clf_gb, param_grid=param_grid, cv=5, scoring='accuracy')\n",
    "\n",
    "# Fit GridSearchCV to the training data\n",
    "grid_search_clf_gb.fit(X_train, y_train)\n",
    "\n",
    "# Retrieve the best model from GridSearchCV\n",
    "best_gb_clf = grid_search_clf_gb.best_estimator_\n",
    "\n",
    "# Make predictions using the best model on the test set\n",
    "pred_gb_clf = best_gb_clf.predict(X_test)\n",
    "\n",
    "# Calculate various performance metrics\n",
    "accuracy_gb = accuracy_score(y_test, pred_gb_clf)\n",
    "precision_gb = precision_score(y_test, pred_gb_clf)\n",
    "recall_gb = recall_score(y_test, pred_gb_clf)\n",
    "f1_gb = f1_score(y_test, pred_gb_clf)\n",
    "\n",
    "# Print the performance metrics\n",
    "print(\"Gradient Boosting Classifier Model Performance Metrics:\")\n",
    "print(\"Accuracy: {:.3f}\".format(accuracy_gb))\n",
    "print(\"Precision: {:.3f}\".format(precision_gb))\n",
    "print(\"Recall: {:.3f}\".format(recall_gb))\n",
    "print(\"F1 Score: {:.3f}\".format(f1_gb))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "25ddb386-c240-4fde-9d20-10175e792465",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters: {'learning_rate': 0.2, 'max_depth': 4, 'n_estimators': 50, 'subsample': 0.6}\n",
      "Best cross-validation accuracy: 0.825\n"
     ]
    }
   ],
   "source": [
    "print(\"Best parameters:\", grid_search_clf_gb.best_params_)\n",
    "print(\"Best cross-validation accuracy:\", grid_search_clf_gb.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "a63c4f43-379e-40fc-8cc7-38ec27ae8756",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGBoost Classifier Model Performance Metrics:\n",
      "Accuracy: 0.700\n",
      "Precision: 0.667\n",
      "Recall: 0.500\n",
      "F1 Score: 0.571\n"
     ]
    }
   ],
   "source": [
    "from xgboost import XGBClassifier\n",
    "\n",
    "# Define XGBClassifier parameters to tune\n",
    "param_grid = {\n",
    "    'n_estimators': [5, 10, 50, 100, 200, 300],\n",
    "    'learning_rate': [0.01, 0.02, 0.1, 0.2, 0.3, 0.5],\n",
    "    'max_depth': [3, 4, 5, 6, 7, 8],\n",
    "    'subsample': [0.5, 0.6, 0.7, 0.8, 0.9, 1.0],\n",
    "    'colsample_bytree': [0.5,0.6,0.7, 0.8, 0.9]  # Percentage of features used per tree\n",
    "}\n",
    "\n",
    "# Initialize the XGBClassifier\n",
    "clf_xgb = XGBClassifier(random_state=500, use_label_encoder=False, eval_metric='logloss')\n",
    "\n",
    "# Initialize GridSearchCV with 'accuracy' as the scoring metric\n",
    "grid_search_clf_xgb = GridSearchCV(estimator=clf_xgb, param_grid=param_grid, cv=5, scoring='accuracy')\n",
    "\n",
    "# Fit GridSearchCV to the training data\n",
    "grid_search_clf_xgb.fit(X_train, y_train)\n",
    "\n",
    "# Retrieve the best model from GridSearchCV\n",
    "best_xgb_clf = grid_search_clf_xgb.best_estimator_\n",
    "\n",
    "# Make predictions using the best model on the test set\n",
    "pred_xgb_clf = best_xgb_clf.predict(X_test)\n",
    "\n",
    "# Calculate various performance metrics\n",
    "accuracy_xgb = accuracy_score(y_test, pred_xgb_clf)\n",
    "precision_xgb = precision_score(y_test, pred_xgb_clf)\n",
    "recall_xgb = recall_score(y_test, pred_xgb_clf)\n",
    "f1_xgb = f1_score(y_test, pred_xgb_clf)\n",
    "\n",
    "# Print the performance metrics\n",
    "print(\"XGBoost Classifier Model Performance Metrics:\")\n",
    "print(\"Accuracy: {:.3f}\".format(accuracy_xgb))\n",
    "print(\"Precision: {:.3f}\".format(precision_xgb))\n",
    "print(\"Recall: {:.3f}\".format(recall_xgb))\n",
    "print(\"F1 Score: {:.3f}\".format(f1_xgb))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "e2f33d27-72fc-49bd-908f-ac85129adc5c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters: {'colsample_bytree': 0.7, 'learning_rate': 0.2, 'max_depth': 3, 'n_estimators': 200, 'subsample': 0.9}\n",
      "Best cross-validation accuracy: 0.825\n"
     ]
    }
   ],
   "source": [
    "print(\"Best parameters:\", grid_search_clf_xgb.best_params_)\n",
    "print(\"Best cross-validation accuracy:\", grid_search_clf_xgb.best_score_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7d57d3f-2730-4f7a-bfdb-71f4f2fee796",
   "metadata": {},
   "source": [
    "# Classification for Variance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "3ed7be43-fe4d-4696-a5c1-f8692e1e6598",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((40, 16), (10, 16), (40,), (10,), (1, 21))"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df4 = pd.read_csv('/Users/patwilliams/DSCI441/DSCI411-project/Data_PreProcessing/final_economic_data.csv')\n",
    "\n",
    "holdout = df4[df4['Year'] == 2024]\n",
    "\n",
    "# Remove the holdout set from the main DataFrame\n",
    "df_modeling = df4[df4['Year'] != 2024]\n",
    "\n",
    "# IF YEAR SHOULD BE INCORPORATED\n",
    "\n",
    "# Calculate 'Years Since Epoch' where Epoch is set to 1974\n",
    "#df['Years_Since_Epoch'] = df['Year'] - 1974\n",
    "# Display the updated DataFrame to verify the transformation\n",
    "#df[['Year', 'Years_Since_Epoch']].head()\n",
    "\n",
    "\n",
    "# Define the features and target\n",
    "X = df_modeling.drop(['Annual_Unemployment_Rate', 'Year', 'Unemployment_Rate_Increased', 'Unemployment_Rate_Percent_Change', 'Unemployment_Rate_Change_Indicator'], axis=1) # should year be included?? Is it better to include as t starting with t = 0... t+1\n",
    "y = df_modeling['Unemployment_Rate_Change_Indicator']\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "# We want 40 observations in the training set, and 10 in the test set\n",
    "# The dataset is already sorted by year, so we can split accordingly\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=10, shuffle=False)\n",
    "\n",
    "# Check the shapes to confirm the sizes\n",
    "(X_train.shape, X_test.shape, y_train.shape, y_test.shape, holdout.shape)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
